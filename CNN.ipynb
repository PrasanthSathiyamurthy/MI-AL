{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a Convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add (Conv2D (32,(3,3), input_shape= (64, 64, 3),activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add (MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a flatennig layer\n",
    "#This transforms the grid values into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add (Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add (Dense(128,activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add (Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile (optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image pre-processing allows us to get a more enriched data set by splitting the dataset into batches and applying random proessing\n",
    "# To create a number of possibilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 3219s 402ms/step - loss: 0.4408 - acc: 0.7869 - val_loss: 0.5752 - val_acc: 0.7780\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2750s 344ms/step - loss: 0.2790 - acc: 0.8797 - val_loss: 0.8701 - val_acc: 0.7656\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 2798s 350ms/step - loss: 0.1948 - acc: 0.9201 - val_loss: 0.9959 - val_acc: 0.7691\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 2899s 362ms/step - loss: 0.1460 - acc: 0.9424 - val_loss: 1.4623 - val_acc: 0.7269\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 1751s 219ms/step - loss: 0.1139 - acc: 0.9567 - val_loss: 1.6312 - val_acc: 0.7441\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 1654s 207ms/step - loss: 0.0916 - acc: 0.9660 - val_loss: 1.6639 - val_acc: 0.7645\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 1669s 209ms/step - loss: 0.0793 - acc: 0.9709 - val_loss: 1.7195 - val_acc: 0.7525\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 1659s 207ms/step - loss: 0.0703 - acc: 0.9743 - val_loss: 2.0137 - val_acc: 0.7511\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 1641s 205ms/step - loss: 0.0624 - acc: 0.9780 - val_loss: 1.9821 - val_acc: 0.7642\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 1637s 205ms/step - loss: 0.0560 - acc: 0.9803 - val_loss: 2.0816 - val_acc: 0.7556\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 1640s 205ms/step - loss: 0.0502 - acc: 0.9822 - val_loss: 2.2567 - val_acc: 0.7558\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 1642s 205ms/step - loss: 0.0466 - acc: 0.9834 - val_loss: 2.1909 - val_acc: 0.7606\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 1640s 205ms/step - loss: 0.0435 - acc: 0.9848 - val_loss: 2.7347 - val_acc: 0.7330\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 1640s 205ms/step - loss: 0.0399 - acc: 0.9863 - val_loss: 2.4913 - val_acc: 0.7534\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 1638s 205ms/step - loss: 0.0383 - acc: 0.9870 - val_loss: 2.3146 - val_acc: 0.7687\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 1643s 205ms/step - loss: 0.0361 - acc: 0.9877 - val_loss: 2.4255 - val_acc: 0.7524\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 1645s 206ms/step - loss: 0.0331 - acc: 0.9889 - val_loss: 2.5559 - val_acc: 0.7626\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 1638s 205ms/step - loss: 0.0321 - acc: 0.9892 - val_loss: 2.5366 - val_acc: 0.7655\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 1646s 206ms/step - loss: 0.0307 - acc: 0.9898 - val_loss: 2.4841 - val_acc: 0.7625\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 1642s 205ms/step - loss: 0.0282 - acc: 0.9906 - val_loss: 2.5713 - val_acc: 0.7616\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 1644s 205ms/step - loss: 0.0266 - acc: 0.9913 - val_loss: 2.8169 - val_acc: 0.7679\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 1643s 205ms/step - loss: 0.0264 - acc: 0.9912 - val_loss: 2.6973 - val_acc: 0.7666\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 1647s 206ms/step - loss: 0.0239 - acc: 0.9919 - val_loss: 2.8829 - val_acc: 0.7567\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 1646s 206ms/step - loss: 0.0244 - acc: 0.9919 - val_loss: 2.7933 - val_acc: 0.7576\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 1652s 206ms/step - loss: 0.0228 - acc: 0.9925 - val_loss: 2.7315 - val_acc: 0.7634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ff7726a888>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('training_set',\n",
    "             target_size=(64, 64), # Matching the image size from CNN\n",
    "             batch_size=32,\n",
    "             class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.fit_generator(training_set,\n",
    "        steps_per_epoch=8000, # no. of samples\n",
    "        epochs=25,\n",
    "        validation_data= test_set,\n",
    "        validation_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
